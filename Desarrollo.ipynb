{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIÓN DEL ABANDONO (BURNOUT) DE EMPLEADOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open(\"datos_grupos/attrition_available_2.pkl\",'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio de Datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos la cantidad de entradas que tenemos en el dataset y los atributos presentes en estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num de instancias y atributos: (4410, 31)\n",
      "Nombre de los atributos: Index(['hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
      "       'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
      "       'Attrition', 'BusinessTravel', 'Department', 'DistanceFromHome',\n",
      "       'Education', 'EducationField', 'EmployeeCount', 'EmployeeID', 'Gender',\n",
      "       'JobLevel', 'JobRole', 'MaritalStatus', 'MonthlyIncome',\n",
      "       'NumCompaniesWorked', 'Over18', 'PercentSalaryHike', 'StandardHours',\n",
      "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
      "       'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"num de instancias y atributos:\", data.shape)\n",
    "print(\"Nombre de los atributos:\", data.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos si existen missing values en los datos; para ello utilizamos el método .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4410 entries, 1 to 4409\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   hrs                      3639 non-null   float64\n",
      " 1   absences                 3575 non-null   float64\n",
      " 2   JobInvolvement           3585 non-null   float64\n",
      " 3   PerformanceRating        3534 non-null   float64\n",
      " 4   EnvironmentSatisfaction  3428 non-null   float64\n",
      " 5   JobSatisfaction          3637 non-null   float64\n",
      " 6   WorkLifeBalance          3620 non-null   float64\n",
      " 7   Age                      3636 non-null   float64\n",
      " 8   Attrition                4410 non-null   object \n",
      " 9   BusinessTravel           3687 non-null   object \n",
      " 10  Department               3575 non-null   object \n",
      " 11  DistanceFromHome         3681 non-null   float64\n",
      " 12  Education                3628 non-null   float64\n",
      " 13  EducationField           4410 non-null   object \n",
      " 14  EmployeeCount            3484 non-null   float64\n",
      " 15  EmployeeID               4410 non-null   int64  \n",
      " 16  Gender                   3523 non-null   object \n",
      " 17  JobLevel                 3641 non-null   float64\n",
      " 18  JobRole                  3625 non-null   object \n",
      " 19  MaritalStatus            3639 non-null   object \n",
      " 20  MonthlyIncome            3579 non-null   float64\n",
      " 21  NumCompaniesWorked       3465 non-null   float64\n",
      " 22  Over18                   3551 non-null   object \n",
      " 23  PercentSalaryHike        3657 non-null   float64\n",
      " 24  StandardHours            3491 non-null   float64\n",
      " 25  StockOptionLevel         3609 non-null   float64\n",
      " 26  TotalWorkingYears        3596 non-null   float64\n",
      " 27  TrainingTimesLastYear    3476 non-null   float64\n",
      " 28  YearsAtCompany           3678 non-null   float64\n",
      " 29  YearsSinceLastPromotion  3628 non-null   float64\n",
      " 30  YearsWithCurrManager     4410 non-null   int64  \n",
      "dtypes: float64(21), int64(2), object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos missing values en la mayoria de atributos.\n",
    "La variable de salida se corresponde con el índice 8 (Attrition) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cada atributo con más detalle; buscando su tipo, si es constante y la proporción de missing values que presenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               hrs\n",
      "NaN       0.174830\n",
      "6.033902  0.000454\n",
      "9.853332  0.000454\n",
      "6.002747  0.000227\n",
      "5.691867  0.000227\n",
      "...            ...\n",
      "6.511941  0.000227\n",
      "8.338820  0.000227\n",
      "6.623272  0.000227\n",
      "6.884605  0.000227\n",
      "6.511790  0.000227\n",
      "\n",
      "[3638 rows x 1 columns]\n",
      "      absences\n",
      "NaN   0.189342\n",
      "7.0   0.049206\n",
      "17.0  0.047846\n",
      "6.0   0.045805\n",
      "14.0  0.045578\n",
      "19.0  0.045578\n",
      "10.0  0.044671\n",
      "8.0   0.044218\n",
      "11.0  0.043991\n",
      "18.0  0.043991\n",
      "15.0  0.043991\n",
      "12.0  0.043311\n",
      "16.0  0.041270\n",
      "13.0  0.040590\n",
      "9.0   0.039683\n",
      "20.0  0.039229\n",
      "5.0   0.038095\n",
      "21.0  0.032653\n",
      "4.0   0.026304\n",
      "22.0  0.020635\n",
      "3.0   0.013605\n",
      "23.0  0.011111\n",
      "2.0   0.006576\n",
      "24.0  0.001587\n",
      "1.0   0.001134\n",
      "     JobInvolvement\n",
      "3.0        0.478912\n",
      "2.0        0.208163\n",
      "NaN        0.187075\n",
      "4.0        0.078912\n",
      "1.0        0.046939\n",
      "     PerformanceRating\n",
      "3.0           0.678458\n",
      "NaN           0.198639\n",
      "4.0           0.122902\n",
      "     EnvironmentSatisfaction\n",
      "3.0                 0.237415\n",
      "4.0                 0.236508\n",
      "NaN                 0.222676\n",
      "2.0                 0.153515\n",
      "1.0                 0.149887\n",
      "     JobSatisfaction\n",
      "4.0         0.256009\n",
      "3.0         0.252608\n",
      "NaN         0.175283\n",
      "1.0         0.161678\n",
      "2.0         0.154422\n",
      "     WorkLifeBalance\n",
      "3.0         0.497959\n",
      "2.0         0.190023\n",
      "NaN         0.179138\n",
      "4.0         0.086621\n",
      "1.0         0.046259\n",
      "           Age\n",
      "NaN   0.175510\n",
      "34.0  0.044898\n",
      "35.0  0.039909\n",
      "31.0  0.038322\n",
      "36.0  0.038322\n",
      "29.0  0.037642\n",
      "38.0  0.034240\n",
      "33.0  0.034014\n",
      "30.0  0.032880\n",
      "32.0  0.032653\n",
      "40.0  0.031066\n",
      "27.0  0.029025\n",
      "28.0  0.028798\n",
      "37.0  0.027438\n",
      "42.0  0.024943\n",
      "39.0  0.024490\n",
      "41.0  0.024036\n",
      "45.0  0.023356\n",
      "26.0  0.020635\n",
      "44.0  0.019728\n",
      "46.0  0.019048\n",
      "43.0  0.016780\n",
      "50.0  0.016780\n",
      "24.0  0.013832\n",
      "25.0  0.013832\n",
      "49.0  0.013605\n",
      "47.0  0.013152\n",
      "55.0  0.012018\n",
      "53.0  0.011111\n",
      "54.0  0.011111\n",
      "51.0  0.010884\n",
      "22.0  0.009977\n",
      "48.0  0.009751\n",
      "52.0  0.009751\n",
      "21.0  0.007937\n",
      "56.0  0.007937\n",
      "23.0  0.007710\n",
      "58.0  0.007029\n",
      "20.0  0.005669\n",
      "19.0  0.005215\n",
      "59.0  0.005215\n",
      "18.0  0.004535\n",
      "60.0  0.002948\n",
      "57.0  0.002268\n",
      "     Attrition\n",
      "No    0.838776\n",
      "Yes   0.161224\n",
      "                   BusinessTravel\n",
      "Travel_Rarely            0.590023\n",
      "NaN                      0.163946\n",
      "Travel_Frequently        0.160317\n",
      "Non-Travel               0.085714\n",
      "                        Department\n",
      "Research & Development    0.530385\n",
      "Sales                     0.245351\n",
      "NaN                       0.189342\n",
      "Human Resources           0.034921\n",
      "      DistanceFromHome\n",
      "NaN           0.165306\n",
      "2.0           0.117687\n",
      "1.0           0.117234\n",
      "10.0          0.051701\n",
      "7.0           0.048753\n",
      "9.0           0.048299\n",
      "3.0           0.046032\n",
      "8.0           0.045351\n",
      "4.0           0.036508\n",
      "5.0           0.036054\n",
      "6.0           0.034014\n",
      "16.0          0.018141\n",
      "24.0          0.016553\n",
      "23.0          0.016327\n",
      "11.0          0.016100\n",
      "18.0          0.015420\n",
      "29.0          0.014739\n",
      "20.0          0.014512\n",
      "25.0          0.014286\n",
      "26.0          0.014059\n",
      "28.0          0.013605\n",
      "15.0          0.013152\n",
      "19.0          0.012472\n",
      "14.0          0.012018\n",
      "12.0          0.012018\n",
      "22.0          0.011565\n",
      "17.0          0.011111\n",
      "21.0          0.009977\n",
      "13.0          0.009977\n",
      "27.0          0.007029\n",
      "     Education\n",
      "3.0   0.322222\n",
      "4.0   0.219955\n",
      "NaN   0.177324\n",
      "2.0   0.158277\n",
      "1.0   0.093651\n",
      "5.0   0.028571\n",
      "                  EducationField\n",
      "Life Sciences           0.412245\n",
      "Medical                 0.315646\n",
      "Marketing               0.108163\n",
      "Technical Degree        0.089796\n",
      "Other                   0.055782\n",
      "Human Resources         0.018367\n",
      "     EmployeeCount\n",
      "1.0       0.790023\n",
      "NaN       0.209977\n",
      "      EmployeeID\n",
      "2       0.000227\n",
      "2658    0.000227\n",
      "2664    0.000227\n",
      "2663    0.000227\n",
      "2662    0.000227\n",
      "...          ...\n",
      "919     0.000227\n",
      "920     0.000227\n",
      "921     0.000227\n",
      "922     0.000227\n",
      "4410    0.000227\n",
      "\n",
      "[4410 rows x 1 columns]\n",
      "          Gender\n",
      "Male    0.481179\n",
      "Female  0.317687\n",
      "NaN     0.201134\n",
      "     JobLevel\n",
      "1.0  0.308390\n",
      "2.0  0.296825\n",
      "NaN  0.174376\n",
      "3.0  0.120862\n",
      "4.0  0.062132\n",
      "5.0  0.037415\n",
      "                            JobRole\n",
      "Sales Executive            0.182766\n",
      "NaN                        0.178005\n",
      "Research Scientist         0.168707\n",
      "Laboratory Technician      0.143991\n",
      "Manufacturing Director     0.080499\n",
      "Healthcare Representative  0.074150\n",
      "Manager                    0.055329\n",
      "Research Director          0.046032\n",
      "Sales Representative       0.043311\n",
      "Human Resources            0.027211\n",
      "          MaritalStatus\n",
      "Married        0.382540\n",
      "Single         0.260544\n",
      "Divorced       0.182086\n",
      "NaN            0.174830\n",
      "          MonthlyIncome\n",
      "NaN            0.188435\n",
      "23420.0        0.002268\n",
      "55620.0        0.002041\n",
      "61420.0        0.002041\n",
      "34520.0        0.001814\n",
      "...                 ...\n",
      "71400.0        0.000227\n",
      "104470.0       0.000227\n",
      "188440.0       0.000227\n",
      "28590.0        0.000227\n",
      "26550.0        0.000227\n",
      "\n",
      "[1340 rows x 1 columns]\n",
      "     NumCompaniesWorked\n",
      "1.0            0.283673\n",
      "NaN            0.214286\n",
      "0.0            0.107029\n",
      "3.0            0.082993\n",
      "2.0            0.076190\n",
      "4.0            0.075057\n",
      "7.0            0.039909\n",
      "6.0            0.035601\n",
      "5.0            0.033787\n",
      "9.0            0.026984\n",
      "8.0            0.024490\n",
      "       Over18\n",
      "Y    0.805215\n",
      "NaN  0.194785\n",
      "      PercentSalaryHike\n",
      "NaN            0.170748\n",
      "11.0           0.115420\n",
      "14.0           0.113832\n",
      "13.0           0.113605\n",
      "12.0           0.112698\n",
      "15.0           0.056916\n",
      "18.0           0.051020\n",
      "17.0           0.048299\n",
      "16.0           0.044218\n",
      "19.0           0.042857\n",
      "20.0           0.032653\n",
      "22.0           0.032200\n",
      "21.0           0.026531\n",
      "23.0           0.016100\n",
      "24.0           0.011791\n",
      "25.0           0.011111\n",
      "     StandardHours\n",
      "8.0        0.79161\n",
      "NaN        0.20839\n",
      "     StockOptionLevel\n",
      "0.0          0.353741\n",
      "1.0          0.326531\n",
      "NaN          0.181633\n",
      "2.0          0.089342\n",
      "3.0          0.048753\n",
      "      TotalWorkingYears\n",
      "NaN            0.184580\n",
      "10.0           0.114966\n",
      "6.0            0.067347\n",
      "8.0            0.057370\n",
      "9.0            0.052834\n",
      "5.0            0.049433\n",
      "7.0            0.045125\n",
      "1.0            0.043764\n",
      "4.0            0.034694\n",
      "12.0           0.027211\n",
      "3.0            0.022902\n",
      "15.0           0.022676\n",
      "16.0           0.021769\n",
      "13.0           0.019728\n",
      "11.0           0.018367\n",
      "21.0           0.018141\n",
      "17.0           0.017914\n",
      "2.0            0.017687\n",
      "14.0           0.016327\n",
      "20.0           0.015873\n",
      "18.0           0.014966\n",
      "23.0           0.012698\n",
      "19.0           0.012472\n",
      "22.0           0.012018\n",
      "24.0           0.010204\n",
      "28.0           0.007937\n",
      "25.0           0.007710\n",
      "26.0           0.007710\n",
      "29.0           0.006576\n",
      "0.0            0.005669\n",
      "32.0           0.005215\n",
      "31.0           0.004989\n",
      "33.0           0.004535\n",
      "27.0           0.004082\n",
      "30.0           0.003401\n",
      "36.0           0.003175\n",
      "34.0           0.002494\n",
      "37.0           0.002268\n",
      "35.0           0.001587\n",
      "40.0           0.001134\n",
      "38.0           0.000454\n",
      "     TrainingTimesLastYear\n",
      "2.0               0.292971\n",
      "3.0               0.265306\n",
      "NaN               0.211791\n",
      "5.0               0.065306\n",
      "4.0               0.064399\n",
      "1.0               0.037868\n",
      "6.0               0.032880\n",
      "0.0               0.029478\n",
      "      YearsAtCompany\n",
      "NaN         0.165986\n",
      "5.0         0.109977\n",
      "1.0         0.098639\n",
      "2.0         0.072562\n",
      "3.0         0.071429\n",
      "10.0        0.068027\n",
      "4.0         0.061905\n",
      "7.0         0.049887\n",
      "9.0         0.046032\n",
      "8.0         0.045578\n",
      "6.0         0.043537\n",
      "0.0         0.026304\n",
      "11.0        0.016780\n",
      "20.0        0.016100\n",
      "13.0        0.014286\n",
      "15.0        0.012018\n",
      "14.0        0.009977\n",
      "22.0        0.009297\n",
      "12.0        0.008844\n",
      "21.0        0.008163\n",
      "18.0        0.007029\n",
      "16.0        0.006803\n",
      "19.0        0.005896\n",
      "17.0        0.004989\n",
      "24.0        0.003628\n",
      "33.0        0.002948\n",
      "31.0        0.002041\n",
      "26.0        0.001814\n",
      "25.0        0.001814\n",
      "32.0        0.001587\n",
      "36.0        0.001361\n",
      "29.0        0.001134\n",
      "23.0        0.000907\n",
      "27.0        0.000680\n",
      "34.0        0.000680\n",
      "30.0        0.000680\n",
      "37.0        0.000454\n",
      "40.0        0.000227\n",
      "      YearsSinceLastPromotion\n",
      "0.0                  0.329478\n",
      "1.0                  0.197506\n",
      "NaN                  0.177324\n",
      "2.0                  0.090476\n",
      "7.0                  0.042404\n",
      "4.0                  0.032880\n",
      "3.0                  0.028345\n",
      "5.0                  0.024263\n",
      "6.0                  0.017460\n",
      "11.0                 0.013152\n",
      "9.0                  0.010204\n",
      "8.0                  0.009751\n",
      "15.0                 0.007256\n",
      "13.0                 0.005669\n",
      "12.0                 0.005669\n",
      "14.0                 0.004762\n",
      "10.0                 0.003401\n",
      "    YearsWithCurrManager\n",
      "2               0.234014\n",
      "0               0.178912\n",
      "7               0.146939\n",
      "3               0.096599\n",
      "8               0.072789\n",
      "4               0.066667\n",
      "1               0.051701\n",
      "9               0.043537\n",
      "5               0.021088\n",
      "6               0.019728\n",
      "10              0.018367\n",
      "11              0.014966\n",
      "12              0.012245\n",
      "13              0.009524\n",
      "17              0.004762\n",
      "14              0.003401\n",
      "15              0.003401\n",
      "16              0.001361\n"
     ]
    }
   ],
   "source": [
    "info = {}\n",
    "for colum in data:\n",
    "    print(data[colum].value_counts(dropna = False, normalize = True ).to_frame())\n",
    "    info[colum] = data[colum].value_counts(dropna = False, normalize = True ).to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos que si una columna solo tiene dos valores (un valor y NaN) esta es constante; en este caso las columnas de Over18 y Standard Hours. Ignoramos la columna de Attrition ya que es nuestra variable objetivo y se trata de una clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attrition\n",
      "No    0.838776\n",
      "Yes   0.161224\n",
      "     EmployeeCount\n",
      "1.0       0.790023\n",
      "NaN       0.209977\n",
      "       Over18\n",
      "Y    0.805215\n",
      "NaN  0.194785\n",
      "     StandardHours\n",
      "8.0        0.79161\n",
      "NaN        0.20839\n"
     ]
    }
   ],
   "source": [
    "for colum in data:\n",
    "    if info[colum].shape[0] < 3:\n",
    "        print(info[colum])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attrition'] = data['Attrition'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya se ha mencionado se trata de un problema de clasificación binaria. Y está desbalanceado (un 83% de la variable de salida se corresponde con una de las clases) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuestro dataset en X e y, ieendo X los atributos y Y la variable de salida. De la misma manera, creamos dos listas para guardar los datos categóricos y numéricos. Además, dividimos los datos en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Attrition\", axis= 'columns')\n",
    "Y = data['Attrition']\n",
    "\n",
    "cat_col = []\n",
    "num_col = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype != \"object\":\n",
    "        num_col.append(col)\n",
    "        continue\n",
    "    cat_col.append(col)\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el preproceso de datos, los valores numéricos serán escalados y sus missing values se imputarán de acuerdo a la mediana. Para los categóricos se aplicará una transformación usando one-hot-encoding y sus missing values se imputarán de acuerdo al más frecuente. Estas dos transformaciones se combinan en el pipeline procesor para ser utilizado más adelante con los diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3528, 50)\n"
     ]
    }
   ],
   "source": [
    "imputer_num = SimpleImputer(strategy='median')\n",
    "scaler = RobustScaler()\n",
    "pipeline_num = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", imputer_num),\n",
    "        (\"scaler\", scaler)\n",
    "    ]\n",
    ")\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "encoder_cat = OneHotEncoder(handle_unknown='ignore')\n",
    "pipeline_cat = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", imputer_cat),\n",
    "        (\"encoder\", encoder_cat)\n",
    "    ]\n",
    ")\n",
    "\n",
    "processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", pipeline_num, num_col),\n",
    "        (\"cat\", pipeline_cat, cat_col),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformed_x = processor.fit_transform(train_x)\n",
    "print(transformed_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_reg = LogisticRegression(class_weight='balanced', random_state=2)\n",
    "\n",
    "predictor = Pipeline(\n",
    "    steps=[\n",
    "        (\"Transformer\", processor),\n",
    "        (\"predictor\", Log_reg)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82       740\n",
      "           1       0.31      0.62      0.42       142\n",
      "\n",
      "    accuracy                           0.72       882\n",
      "   macro avg       0.61      0.68      0.62       882\n",
      "weighted avg       0.81      0.72      0.75       882\n",
      "\n",
      "\n",
      "Matriz de confusión: \n",
      "\n",
      " [[547 193]\n",
      " [ 54  88]]\n",
      "Score f1:\n",
      " 0.4160756501182033\n"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_x, train_y)\n",
    "\n",
    "pred = predictor.predict(test_x)\n",
    "\n",
    "print(\"Clasification report: \\n\\n\",classification_report(test_y, pred, zero_division=0))\n",
    "print( \"\\nMatriz de confusión: \\n\\n\", confusion_matrix(test_y, pred))\n",
    "print(\"\\nScore f1:\\n\", f1_score(test_y, pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clas = GradientBoostingClassifier(random_state=2)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.05, 0.01]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(gb_clas, param_grid, cv=cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "predictor = Pipeline(\n",
    "    steps=[\n",
    "        (\"Transformer\", processor),\n",
    "        (\"predictor\", grid)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       740\n",
      "           1       0.93      0.55      0.69       142\n",
      "\n",
      "    accuracy                           0.92       882\n",
      "   macro avg       0.92      0.77      0.82       882\n",
      "weighted avg       0.92      0.92      0.91       882\n",
      "\n",
      "\n",
      "Matriz de confusión: \n",
      "\n",
      " [[734   6]\n",
      " [ 64  78]]\n",
      "Score f1:\n",
      " 0.6902654867256638\n"
     ]
    }
   ],
   "source": [
    "predictor.fit(train_x, train_y)\n",
    "pred = predictor.predict(test_x)\n",
    "\n",
    "print(\"Clasification report: \\n\\n\",classification_report(test_y, pred, zero_division=0))\n",
    "print(\"\\nMatriz de confusión: \\n\\n\", confusion_matrix(test_y, pred))\n",
    "print(\"\\nScore f1:\\n\", f1_score(test_y, pred, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(random_seed=2, verbose=0, class_weights= [1, 5.2])\n",
    "\n",
    "param_grid = { 'iterations': [100, 200, 300],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'depth': [4, 6, 8],\n",
    "    'border_count': [32, 64, 128]  \n",
    "}\n",
    "\n",
    "cat_grid = GridSearchCV(catboost, param_grid, cv=cv, scoring='balanced_accuracy', n_jobs=-1)\n",
    "\n",
    "cat_predictor = Pipeline(\n",
    "    steps=[\n",
    "        (\"Transformer\", processor),\n",
    "        (\"predictor\", cat_grid)\n",
    "    ]\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       740\n",
      "           1       0.67      0.65      0.66       142\n",
      "\n",
      "    accuracy                           0.89       882\n",
      "   macro avg       0.80      0.80      0.80       882\n",
      "weighted avg       0.89      0.89      0.89       882\n",
      "\n",
      "\n",
      "Matriz de confusión: \n",
      "\n",
      " [[695  45]\n",
      " [ 49  93]]\n",
      "Score f1:\n",
      " 0.6642857142857143\n"
     ]
    }
   ],
   "source": [
    "cat_predictor.fit(train_x, train_y)\n",
    "pred = cat_predictor.predict(test_x)\n",
    "\n",
    "print(\"Clasification report: \\n\\n\",classification_report(test_y, pred, zero_division=0))\n",
    "print(\"\\nMatriz de confusión: \\n\\n\", confusion_matrix(test_y, pred))\n",
    "print(\"\\nScore f1:\\n\", f1_score(test_y, pred, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo entrenado y evaluado todos los modelos, podemos observar que el regresor logístico presenta el mayor error. Por lo que lo podemos descartar como la opción óptima. Por otra parte los modelos de gradientboost y catboosting presentan un error similar, siendo el gradientboost el que presenta una fq_score algo mayor. Por lo que podemos concluir que el modelo de gradientboost es el que mejor se ajusta a nuestro problema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez evaluados los tres modelos; elegimos el mejor de estos (gradientboost) para probar si reduciendo el número de atributos obtenemos mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       740\n",
      "           1       0.69      0.68      0.68       142\n",
      "\n",
      "    accuracy                           0.90       882\n",
      "   macro avg       0.81      0.81      0.81       882\n",
      "weighted avg       0.90      0.90      0.90       882\n",
      "\n",
      "\n",
      "Matriz de confusión: \n",
      "\n",
      " [[696  44]\n",
      " [ 46  96]]\n",
      "\n",
      "Score f1:\n",
      " 0.6808510638297872\n"
     ]
    }
   ],
   "source": [
    "selectk = SelectKBest(score_func=f_classif, k=40)\n",
    "\n",
    "Selector = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", processor),\n",
    "        (\"variance_threshold\", VarianceThreshold()),\n",
    "        (\"kbest\", selectk),\n",
    "        (\"predictor\", GradientBoostingClassifier(**grid.best_params_, random_seed= 2, verbose=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_best = Selector.fit(train_x,train_y)\n",
    "pred = X_best.predict(test_x)\n",
    "\n",
    "print(\"Clasification report: \\n\\n\",classification_report(test_y, pred, zero_division=0))\n",
    "print(\"\\nMatriz de confusión: \\n\\n\", confusion_matrix(test_y, pred))\n",
    "print(\"\\nScore f1:\\n\", f1_score(test_y, pred, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque la diferencia no sea muy elevada, podemos observar una mejoría del rendimiento. Quizás el conjunto de test sea demasiado pequeño como para afirmar con certeza que aplicar la reducción de atributos es positiva; pero nosotros nos decantamos de forma favorable hacia esta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
